	% Lecture Notes in Computer Science Latex2e Style file,
% ftp://ftp.springer.de/pub/tex/latex/llncs/latex2e/llncs2e.zip
%
% $Revision$
% $Date$
% $Log$
% Revision 1.10  2005/12/15 15:29:20  jonblower
% After significant reworking, esp. of introduction
%
% Revision 1.9  2005/12/15 09:14:23  jonblower
% Starting to re-write introduction
%
% Revision 1.8  2005/12/14 17:19:31  jonblower
% Near-complete first draft, plus references
%
% Revision 1.7  2005/12/14 14:50:52  abharrison
% first stab a web service sections
%
% Revision 1.6  2005/12/14 14:01:29  jonblower
% Added stuff on command-line clients
%
% Revision 1.5  2005/12/14 10:13:32  abharrison
% intro bit the web services section
%
% Revision 1.4  2005/12/14 09:17:20  jonblower
% Continued development
%
% Revision 1.3  2005/12/13 17:59:24  jonblower
% Added introductory material and the SGS namespace
%
% Revision 1.2  2005/12/13 15:28:22  jonblower
% Initial import
%

\documentclass{llncs}
%
\begin{document}
%
\title{Styx Grid Services: Lightweight, easy-to-use middleware for e-Science workflows}
%
\titlerunning{Styx Grid Services}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Jon Blower\inst{1} \and Andrew Harrison\inst{2}
\and Keith Haines\inst{1} \and Ed Llewellin\inst{3}}
%
\authorrunning{J. Blower et al.}   % abbreviated author list (for running head)
%
%%%% modified list of authors for the TOC (add the affiliations)
\tocauthor{Jon Blower (University of Reading),
Andrew Harrison (University of Cardiff),
Keith Haines (University of Reading),
Ed Llewellin (University of Cambridge)}
%
\institute{Reading e-Science Centre, Environmental Systems Science Centre,
University of Reading, Reading RG6 6AL, UK\\
\email{jdb@mail.nerc-essc.ac.uk},\\
\and
University of Cardiff, Cardiff, UK
\and
University of Cambridge, Cambridge UK}

\maketitle              % typeset the title of the contribution

\begin{abstract}
(70-150 words)
\end{abstract}
%
\section{Introduction}
The concept of ``workflow'' in e-Science terminology refers to the composition of Internet-based services (such as Web Services) in order to create a distributed application.  For example, a scientist might wish to extract data from a number of data archives in different physical locations, perform some analysis on these data on a high-performance computing (HPC) resource in another location, then produce some visualization of the end result on his or her local machine.  All the services in this workflow are mutually independent (``loosely coupled'') and may be hosted by a number of different service providers.  A workflow is therefore rather like a computer program that brings together a number of high-level components.

In theory, this approach should allow scientists with little technical knowledge to create powerful distributed applications.  In practice, however, there are -- at the time of writing -- very few examples of scientific communities that have started to work in this way on a routine basis.  A large part of the reason for this is the paucity of services that are available for scientists to use: for example, in the environmental sciences community there are Web Services available for accessing environmental data (e.g.\ \cite{Woolf:2003}) but very few services exist for processing or visualizing data.

\subsection{Web Services and workflows}\label{sec:webservices}
Web Services are perhaps the most common type of Internet-based service used by e-Science projects.  They provide very significant advantages for creating loosely-coupled, interoperable services: they are accessed through XML messaging and are thus inherently cross-platform, they are self-describing (through Web Services Definition Language, WSDL~\cite{WSDL} documents) and are a widely-accepted standard for distributed computing.  However, they do not solve all the problems required to create typical scientific workflows and this is part of the reason why the Web Services approach has not yet found wide acceptance in the scientific community.  The key issues are:

\begin{itemize}
	\item {\bf Data transfer:} It is impractical to encode anything but a trivial amount of data in XML due to the processing time required and the inflating effect of doing so.  Other channels (e.g.\ GridFTP, REF) must be employed to transfer moderate or large amounts of data between Web Services.
	\item {\bf Firewall problems:} Scientific services are often long-running and so it is highly desirable to be able to monitor the progress and status of the service as it runs.  One approach is to have the client continuously poll the service for its state but this is not a scalable solution.  Frameworks such as OGSI (REF) and WS-RF use an asynchronous notification mechanism~\cite{wsrf-notification} in which clients run a server process that listens for notification messages.  However, if the client is behind a firewall or a Network Address Translation (NAT) router (a very common situation), these messages will never arrive and, worse, the client will not know why.
	\item {\bf Modelling as RPC:} SOAP Web Services can be either RPC (remote procedure call)-style or document-style.  It is easier for workflow engines to integrate with RPC-style services but it is often difficult to model the complexities of a realistic scientific application as a remote procedure call.
\end{itemize}

If scientists are to adopt the workflow approach in their work, there must exist a set of useful services from which these workflows can be constructed.  In order to create such a ``critical mass'' of services, it must be possible for the {\em scientist\/} to be able to create such services with minimal or no help from dedicated technical staff.  Several systems exist to make the task of creating Web and Grid Services easier (e.g.\ Soaplab, GEMLCA, XXX).  However, these systems are still typically difficult for scientists to use: either because they are not familiar with the Web or Grid Services model or because the systems are based on complex, heavyweight toolkits such as Globus (REF), which are designed for application builders, not end users.  Therefore, technical support is needed to create these services and the critical mass of useful services is never reached.

\subsection{A new approach: Styx Grid Services}
The purpose of this paper is to present a solution that addresses all of the above issues.  We focus on the process of creating services that are based on command-line programs (which may be tried-and-tested ``legacy'' code) but the principles we describe could be extended to other service types, such as those that represent databases, sensors et cetera.  The solution we present deliberately moves away from the Web Services model but, as we shall see, we can still maintain a high level of interoperability.

We introduce the Styx Grid Services (SGS) system, a framework for wrapping command-line (i.e.\ non-graphical) programs and allowing them to be run as a service from anywhere on the Internet.  The major advantages are:
\begin{itemize}
	\item Remote services can be used {\em exactly\/} as if they were locally-installed programs.
	\item Workflows can be created using simple shell scripts or graphical tools.
	\item Data can be streamed directly between remote service instances.
	\item The software is very lightweight and quick to install (less than 5~MB, including all dependencies).
	\item The software places few demands on firewalls, requiring only one incoming port to be open on the server and {\em no\/} incoming ports to be open on client machines.
\end{itemize}

Sect.~\ref{sec:sgsoverview} gives an overview of the SGS system, BLAH ...


\section{Styx Grid Services: overview}\label{sec:sgsoverview}
The goal of the Styx Grid Services system is to make the use of remote services just as easy as using local programs.  The system is heavily influenced by the Inferno~\cite{Inferno} operating system, which is designed from the ground up for distributed computing.  Applications in Inferno treat local and remote resources {\em identically\/}, in fact they know nothing about the location of the resources on which they operate.

This is achieved because of two things: Firstly, in Inferno, all resources are represented as a file or set of files (analogous to the representation of the mouse as {\tt /dev/mouse} in Unix variants).  Secondly, there is a mechanism for sharing files across networks: this is the Styx protocol.  Applications do not know whether they are operating on local or remote files: they simply produce and consume Styx messages, which are routed by the underlying operating system (Inferno) to their destination.

The key to this useful behaviour is the Styx protocol itself~\cite{Pike:1999} (Styx is also used in the Plan~9 operating system~\cite{Plan9}, in which it is known as ``9P'').  The basis of the Styx Grid Services system is a pure-Java implementation of Styx, known as JStyx ({\tt http://jstyx.sf.net}).  Styx is a very small, lightweight protocol since it only needs to contain file commands such as ``open'', ``close'', ``read'' and ``write'' and so Styx-based distributed systems benefit from this efficiency.

All resources in Styx systems are represented as a hierarchy of files, which is known as a {\em namespace\/}.  The Styx Grid Services system specifies a namespace that represents a remotely-installed program.  Clients interact with this program by reading from and writing to special files in this namespace.  For example, the namespace contains an {\tt inputs/} directory, to which clients write the input files necessary for the program to run.  For full details of the SGS namespace see the project website ({\tt http://jstyx.sf.net/sgs}).

Due to this hierarchical structure, every resource on a Styx server can be represented very naturally as a URL.  For example, the file that represents the standard output stream of instance 1 of the the {\tt mySGS} service can be represented by the URL {\tt styx://<server>:<port>/mySGS/instances/1/outputs/stdout}.  This is very important in the context of workflows: these URLs may be passed between services in a workflow to enable direct transfer of data between services (see Sect.~\ref{sec:datastreaming}).

The Styx protocol itself deliberately does not mandate any particular security mechanism.  Transport-level security (TLS) fits very naturally with the Styx model, with client and server being mutually authenticated through public-key certificates.  All Styx traffic can then be encrypted.


\section{Wrapping programs as Styx Grid Services}
Neither service providers nor end-users need to know anything about the details discussed in Sect.~\ref{sec:sgsoverview} above.  The process of wrapping a command-line program as a Styx Grid Service is very simple.  An XML description of the program in question must be constructed; currently this must be done by hand but better tools may be created in future.  This description is a complete specification of the program, specifying the command-line parameters and input files that the program expects and the output files that the program produces.  (There is other optional information that can be added, but that is beyond the scope of this paper.)  A server program is then run, which parses the XML file and sets up the SGS namespace.  A single server can contain many Styx Grid Services.

For example, consider a program called {\tt calc\_mean} that reads a set of input files (perhaps from a set of scientific experiments), calculates their mean and writes the mean data to an output file.  The command line syntax for running this program is:

\begin{verbatim}
calc_mean -i <inputfiles> -o <outputfile>
\end{verbatim}

The program reads one input file that is given by the flag ``-i'' and produces one output file that is given by the flag ``-o''.  This program can be exposed as a Styx Grid Service with the following configuration file:

\begin{verbatim}
<gridservice name='calc_mean' command='/path/to/calc_mean'>
  <params>
    <param name='inputfiles' paramType='flaggedOption' flag='i'/>
    <param name='outputfile' paramType='flaggedOption' flag='o'/>
  </params>
  <inputs>
    <input type='fileFromParam' name='inputfiles'/>
  </inputs>
  <outputs>
    <output type='fileFromParam' name='outputfile'/>
  </outputs>
</gridservice>
\end{verbatim}

\subsection{Executing SGSs just like local programs}

Once the program is deployed as a Styx Grid Service, it can be run from anywhere on the Internet.  A key feature of the system is that the SGS can be run {\em exactly as if it were a local program\/}.  The {\tt SGSRun} program is a general-purpose command-line client program for any Styx Grid Service.  If the {\tt calc\_mean} service were deployed on the server {\tt remotehost.com}, listening on port 9092, the user would run the service by entering the following command:

\begin{verbatim}
SGSRun remotehost.com 9092 calc_mean -i input.dat -o output.dat
\end{verbatim}

It is then an easy task to create a simple wrapper script called {\tt calc\_mean} on the client.  This wraps the {\tt SGSRun} program and contains the location and port of the remote server.  Then this wrapper script can then be treated exactly as if it were the {\tt calc\_mean} program itself.

The {\tt SGSRun} program performs the following tasks:  It connects to the server and downloads the XML description of the Styx Grid Service that it is being asked to run.  It uses this description to parse the command-line arguments that the user has provided.  If these are valid, it creates a new instance of the service and sets its parameters, based on these command-line arguments.  It then uploads the necessary input files, starts the service running and downloads the output data as the service is running.  If the SGS uses the standard streams (stdout, stderr and stdin) these are redirected to and from the console as appropriate.


\section{Creating workflows from Styx Grid Services}

\subsection{Using shell scripts as workflows}
Given that remote SGSs can be executed exactly like local programs, a natural extension is to create workflows by writing simple shell scripts.  Workflows are simply high-level programs and so it is natural to use a scripting environment (REF Geodise).  Let us consider a simple workflow of two Styx Grid Services.  The first is the {\tt calc\_mean} service from the above example.  The second SGS, called {\tt make\_pic} takes a single input file and turns it into a picture.

Imagine that the user has a set of input files (called {\tt input1.dat}, {\tt input2.dat} etc.) and wants to calculate their mean, then produce a picture of the result.  The shell script that he or she would use to execute the necessary workflow in the SGS system would be:

\begin{verbatim}
calc_mean -i input*.dat -o means.dat
make_pic -i means.dat -o means.gif
\end{verbatim}

Note that this is {\em exactly the same script\/} as would be used to invoke the programs if they were installed locally.  (This assumes that the user has created simple shell scripts called {\tt calc\_mean} and {\tt make\_gif} that invoke the {\tt SGSRun} program as described above.)

\subsubsection{Direct data passing.}
The above ``workflow'' (shell script) is very simple but not optimally efficient.  The intermediate file {\tt means.dat} is not required by the user: it is simply uploaded to the {\tt make\_pic} service as soon as it is downloaded.  This wastes time and bandwidth.  The intermediate file can be {\em passed directly between the services\/} with only a minor change to the script:

\begin{verbatim}
calc_mean -i input*.dat -o means.dat.sgsref
make_pic -i means.dat.sgsref -o means.gif
\end{verbatim}

The {\tt .sgsref} extension is a signal to the system to download a {\em reference\/} (URL) to the output file and place it in the file {\tt means.dat.sgsref}.  This reference is then passed to the {\tt make\_pic} service, which downloads the real file directly from the {\tt calc\_mean} service.  Hence this intermediate file does not pass through the workflow enactor (i.e.\ the client's machine).  See Fig.~\ref{fig:datapassing}.

\begin{figure}
\caption{Illustration of direct data passing between Styx Grid Services}\label{fig:datapassing}
\end{figure}

\subsubsection{Data streaming using the pipe operator.}\label{sec:pipes}
As a modification to the above example, let us imagine that the {\tt calc\_mean} program outputs data on its standard output, instead of to an output file.  Similarly, imagine that the {\tt make\_pic} program reads data on its standard input and outputs the picture on its standard output.  The script required to execute this simple workflow (with both local programs {\em and\/} Styx Grid Services) is:

\begin{verbatim}
calc_mean -i input*.dat | make_pic > means.gif
\end{verbatim}

Here, the intermediate data is being streamed to the local client, then streamed back out to the {\tt make\_pic} service.  Again, we can ensure that the intermediate data are streamed directly between the services with a minor change to the script:

\begin{verbatim}
calc_mean -i input*.dat --sgs-ref-stdout | make_pic > means.gif
\end{verbatim}

The {\tt ---sgs-ref-stdout} flag is a signal to send a reference (URL) to the standard output of the {\tt calc\_mean} service to the standard input of the {\tt make\_pic} service.  In this way the intermediate data are streamed directly between the services, across the Internet.

\subsection{Using graphical workflow tools}
The command line scripting interface to the SGS system that is described above is perhaps the simplest way of creating SGS workflows.  In some cases, however, there are significant advantages in using more sophisticated graphical tools to interact with services and create workflows.  In particular, graphical interfaces can provide richer interactivity with the SGS server: progress and status can be monitored graphically, input parameters can be set using graphical controls and the service can be steered.  Some users prefer to use graphical tools to creating their own scripts.

The Taverna workbench ({\tt http://taverna.sf.net}) is a graphical workflow system that was designed for performing {\it in silico} experiments in the field of bioinformatics and it is also useful to other communities.  Using Taverna, the user can build workflows from diverse service types, including Styx Grid Services, Web Services and XXX.  (Screenshot of Taverna executing an SGS workflow?)

The Triana workflow system ({\tt http://trianacode.org}) is another graphical workflow environment that can interface with many different service types.  Although direct support for Styx Grid Services is not built in to Triana at the time of writing, a previous paper~\cite{blower:2005} showed that Styx Grid Services can be wrapped as Web Services, then Triana can be used to run workflows in which data are streamed directly from service to service.

\subsubsection{Asynchronous notification in the SGS system.}
We have discussed (Sect.~\ref{sec:webservices}) the problems faced when implementing asynchronous notification systems in Web Services environments: the notification replies to the clients are often blocked by firewalls or NAT.  BLAH...


\section{Styx Grid Services, Web Services and WS-RF}\label{sec:wsrf}

A compelling argument for employing Web services is that through the use of open standards of service description and message exchange such as WSDL and SOAP, diverse underlying resources and codes can interact. While SOAP, WSDL and the plethora of WS-* specifications are useful for describing service entry points and constraints such as security and policy, they are not necessarily ideal for data intensive, or long-running interactions as are often required in Grid computing. In situations such as these, it can be useful to view these Web service standards as comprising a service level which sits above and specifies an underlying execution layer. This execution layer may use different mechanisms for transferring data such GridFTP or, in the case of SGSs, the Styx protocol. The following two sub-sections describe applications of the SGS framework that make use of Web service standards while still maintaining the integral strengths of the Styx protocol within the context of workflow.

\subsection{Wrapping SGSs as Web Services}
AHM 2004 paper~\cite{blower:2004} ...

Another approach to wrapping SGSs as Web services has been implemented by WSPeer~\cite{wspeer}. WSPeer is a Peer-to-Peer oriented API for hosting and invoking Web services which has a binding to the jstyx libraries allowing SOAP messaging to take place using the Styx protocol. In this scenario WSPeer launches as `SOAP capable' Styx service, that is, the service is conceptually an XML document. The SGS namespace is not externally accessible. Instead the client has access to a WSDL file which defines service operations that encapsulate the messages and data to be written to the namespace files. So for example, to write to the \texttt{stdout} file of an SGS, the client invokes the \texttt{setStdout(String uri)} operation defined in the WSDL. The service endpoint contained in the WSDL is the URI of a file to which these messages can be written. The client invocation triggers WSPeer to write the XML to the service file. The service file processes the SOAP message and reads/writes from its parameter files, setting its own file content accordingly. If WSPeer is expecting a response from the service file it has just written to, it subsequently performs a read operation on the file.

\subsection{Wrapping SGSs as WS-Resources}
\label{subsec:ws-resources}

The Web Services Resource Framework (WS-RF) is a recent specification which addresses the need to handle resources that maintain state across service invocations. These resources, called WS-Resources, can be anything from a database entry, to a subscription, to a job running on a Grid. SGSs fit naturally into this class of network entity because they maintain state which can be retrieved and modified. We have explored wrapping SGSs as WS-Resources using WSPeer which supports WS-RF~\cite{wsrf}.

\sloppypar A WS-Resource is defined as a series of \emph{ResourceProperties}, essentially QName/value pairs of a specified data type. These properties are exposed in the WSDL of a service (a WS-RF service) capable of handling certain WS-Resources. ResourceProperties are common to types of resources and therefore a WS-RF service can manage any number of instances of a type of resource. The reference to an instance of a resource which the service acts upon is sent by the client in the header part of the SOAP message. A WS-RF service may also define operations that act on WS-Resources.

The process of exposing an SGS as a WS-Resource involves parsing the \texttt{config} file in the SGS namespace and transforming the configuration data into ResourceProperties. This is not difficult because the configuration file is machine processable. Furthermore SGS defines certain properties which map directly onto WS-RF related specifications. An example of this is the \texttt{time} directory in the SGS namespace which houses files containing data pertinent to the lifetime of the service. These are reflected in properties defined in the WS-ResourceLifetime~\cite{wsrf-lifetime} specification.

There are two types of WS-RF service that can expose a WS-Resource wrapped SGS using WSPeer:

\begin{enumerate}
\item A SOAP capable WS-RF Styx service using the styx protocol to send and receive XML.
\item A broker WS-RF service. In this case the service uses HTTP.
\end{enumerate}

An important specification related to WS-RF is WS-Notification~\cite{wsrf-notification}. WS-Notification allows clients to be notified of events fired by topics that they have previously subscribed to. In terms of SGS, a number of files are suitable candidates for being exposed as topics in the WSDL of the WS-RF service, particularly the \texttt{serviceData} files. When the WS-Peer generated WS-RF service is using the Styx protocol, these notifications can take the form of pseudo-notifications as described in Section [IS IT DESCRIBED?] allowing clients behind firewalls and Network Address Translation systems to receive notifications. When the server is running over HTTP, the standard notification exchange occurs.

The \texttt{stdout} file of an SGS is important in terms of workflow because it allows data to flow directly between applications rather than via a workflow editor or controller. In terms of wrapping an SGS as a WS-Resource, it is worth noting that this file is not a good candidate for being exposed as a topic  because the notification messages defined by WS-Notification are verbose and designed for discreet events. Attempting to stream voluminous amounts of data using this mechanism would be disastrous. Instead the wrapping should understood in terms of a service and execution level. The URI that the \texttt{stdout} file contains can be set using standard WS-RF message exchanges. The actual data transfer however, should remain in the styx domain which is less self-decribing but more efficient.


\section{Conclusions}

HERE'S SOME MATERIAL THAT COULD BE ADDED IN THE SECTIONS ABOVE IF WE HAVE SPACE

There are many reasons for wishing to expose a program as a service:
\begin{itemize}
	\item The code must run on a powerful resource (e.g.\ a compute cluster) but users want to access the code from a more modest machine, such as a laptop.
	\item The code is tied to a particular platform (e.g. 64-bit Solaris) but users want to access the code from other platforms.
	\item The code has many dependencies (on particular versions of libraries for example) and the exposure of the code as a service removes the need for users to install all these dependencies.
	\item The code depends on data from a large data archive and so should run on a machine that is close to the archive.  However, users want to run the code from anywhere on the Internet.
	\item The code is useful to a wide community and the provision of the code as a service removes the need for multiple users to install it locally.
\end{itemize}

%
In the SGS system, the direct passing of data between service instances is achieved very simply.  The workflow enactor (whether it be a graphical or command-line tool) passes {\em references\/} (i.e.\ URLs) to the data sources from one service to the next.  As an illustration of this, consider a simple workflow involving two services, A and B, in which the output of service A is passed as an input to service B:
\begin{enumerate}
	\item The workflow enactor creates a new instance of service A and starts it running.
	\item {\em Without waiting for service A to finish\/}, the enactor creates a new instance of service B.
	\item The enactor passes a reference (URL) to the output of service A to the appropriate input of service B.
	\item The enactor starts service B.  Service B then downloads the output data from service A as it runs.
\end{enumerate}

%


\section{Interactivity} \label{sec:interactivity}
Something on computational steering...


\section*{Acknowledgements}
Tom Oinn, Inferno guys, Trustin Lee ...
%
% ---- Bibliography ----
%
\bibliographystyle{splncs}
\bibliography{refs}

\end{document}
